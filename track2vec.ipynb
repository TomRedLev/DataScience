{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deezer playlist dataset et recomandandation de morceaux avec word2vec\n",
    "\n",
    "Dans ce mini projet nous allons mettre au point un réseau word2vec et nous en servir pour construire un outils de complétion de playlist (suggestion de morceaux). Les données sont hébergée sur le dépot suivant : http://github.com/comeetie/deezerplay.git. Pour en savoir plus sur word2vec et les données que nous allons utiliser vous pouvez lire les deux références sivantes :\n",
    "\n",
    "- Efficient estimation of word representations in vector space, Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. (https://arxiv.org/abs/1301.3781)\n",
    "- Word2vec applied to Recommendation: Hyperparameters Matter, H. Caselles-Dupré, F. Lesaint and J. Royo-Letelier. (https://arxiv.org/pdf/1804.04212.pdf)\n",
    "\n",
    "Les éléments que vous devez réaliser sont mis en évidence en <span style=\"color:red\">rouge</span> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Préparation des données\n",
    "Les données sont sous la forme d'une liste de playlist. Chaque playlist est elle me une liste avec l'identifiant deezer du morçeau suivi de l'identifiant de l'artiste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[100000, 24.21338]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chargement des données de playlist\n",
    "import numpy as np\n",
    "data = np.load(\"./music_2.npy\",allow_pickle=True)\n",
    "[len(data), np.mean([len(p) for p in data])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le jeu de données sur lequel nous allons trvailler contient 100000 playlist qui sont composeer d'en moyenne 24.1 morceaux. Nous allons commencer par ne conserver que les identifiants de morceau. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separation des ids de morçeau et d'artist\n",
    "playlist_track = [list(filter(lambda w: w.split(\"_\")[0]==u\"track\",playlist)) for playlist in data]\n",
    "playlist_artist = [list(filter(lambda w: w.split(\"_\")[0]==u\"artist\",playlist)) for playlist in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "338509"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nombre de morceaux != ?\n",
    "tracks = np.unique(np.concatenate(playlist_track))\n",
    "Vt = len(tracks)\n",
    "Vt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['track_354917971',\n",
       " 'track_354917981',\n",
       " 'track_354917991',\n",
       " 'track_354918001',\n",
       " 'track_354918011',\n",
       " 'track_405992352',\n",
       " 'track_383552261',\n",
       " 'track_397746652',\n",
       " 'track_385499681',\n",
       " 'track_402932992',\n",
       " 'track_398786652',\n",
       " 'track_357037431',\n",
       " 'track_378113751',\n",
       " 'track_354918011',\n",
       " 'track_403520542',\n",
       " 'track_393157072',\n",
       " 'track_354165291',\n",
       " 'track_357083271',\n",
       " 'track_361171651',\n",
       " 'track_145501426',\n",
       " 'track_397141342',\n",
       " 'track_145370202']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "playlist_track[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le nombre de morceaux différents dans ce data-set est assez élevé avec plus de 300 000 morceaux."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création d'un dictionnnaire de morceau\n",
    "Nous allons affecter a chaque morceau un entier qui nous servira d'identifiant unique et d'entrée pour notre réseau. Pour économiser un peu nos ressources nous allons travailler dans ce TP que sur les morceaux qui apparaissent dans au moins deux playlists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nombre d'occurence de chaque morceaux ?\n",
    "track_counts = dict((tracks[i],0) for i in range(0, Vt))\n",
    "for p in playlist_track:\n",
    "    for a in p:\n",
    "        track_counts[a]=track_counts[a]+1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrage des morceaux peu fréquent pour gangner un peu de temps au vue de nos ressource en temps de calcul  \n",
    "playlist_track_filter = [list(filter(lambda a : track_counts[a]> 1, playlist)) for playlist in playlist_track]\n",
    "# recupération des comptage\n",
    "counts  =  np.array(list(track_counts.values()))\n",
    "# trie\n",
    "order = np.argsort(-counts)\n",
    "# création de notre liste d'identifiant deezer\n",
    "tracks_list_ordered = np.array(list(track_counts.keys()))[order]\n",
    "# Taille de notre vocabulaire = nombre de morçeau conservés\n",
    "Vt=np.where(counts[order]==1)[0][0]\n",
    "# construction d'un dict id_morceaux id [0,Vt]\n",
    "track_dict = dict((tracks_list_ordered[i],i) for i in range(0, Vt))\n",
    "# conversion des playlist en liste d'entier\n",
    "corpus_num_track = [[track_dict[track] for track in play ] for play in playlist_track_filter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[313,\n",
       " 436,\n",
       " 259,\n",
       " 521,\n",
       " 66,\n",
       " 235,\n",
       " 152,\n",
       " 56,\n",
       " 116,\n",
       " 71,\n",
       " 505,\n",
       " 113,\n",
       " 217,\n",
       " 66,\n",
       " 277,\n",
       " 527,\n",
       " 348,\n",
       " 848,\n",
       " 378,\n",
       " 465,\n",
       " 532,\n",
       " 2016]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_num_track[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création des ensembles d'apprentissage de test et de validation\n",
    "\n",
    "Pour apprendre les paramètre de notre méthode nous allons conserver les $l-1$ premiers morceaux de chaque playlist (avec $l$ la longueur de la playlist) pour l'apprentissage. Pour évaluer les performances de completion de notre méthode nous conservons pour chaque playlist les deux derniers morceaux. L'objectif sera de trouver le dernier a partir de l'avant dernier. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensemble de test et d'apprentissage\n",
    "index_tst = np.random.choice(100000,20000)\n",
    "index_val = np.setdiff1d(range(100000),index_tst)\n",
    "# le debut de chaque playlist est conservé pour l'apprentissage\n",
    "play_app  = [corpus_num_track[i][:(len(corpus_num_track[i])-1)] \n",
    "             for i in range(len(corpus_num_track)) if len(corpus_num_track[i])>1]\n",
    "# les deux derniers élemnts pour le test et la validation\n",
    "play_tst  = np.array([corpus_num_track[i][(len(corpus_num_track[i])-2):len(corpus_num_track[i])] \n",
    "             for i in index_tst if len(corpus_num_track[i])>3])\n",
    "play_val  = np.array([corpus_num_track[i][(len(corpus_num_track[i])-2):len(corpus_num_track[i])] \n",
    "             for i in index_val if len(corpus_num_track[i])>3])[:10000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 17:49:44.519829: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-03-28 17:49:44.519845: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "# import de Keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Embedding, Reshape, Activation, Input, Dense,Flatten\n",
    "from keras.layers.merge import Dot\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.sequence import skipgrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hyper-paramètres de word2vec :\n",
    "\n",
    "La méthode word2vec fait intervennir un certains nombre d'hyper paramètres. Nous allons les définirs et leurs donner des première valeurs que nous affinerons par la suite:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimension de l'espace latent\n",
    "vector_dim = 30\n",
    "# taille de la fenêtre de voisinage\n",
    "window_width = 3\n",
    "# sur-échantillonage des exemples négatifs\n",
    "neg_sample = 5\n",
    "# taille des mini-batch\n",
    "min_batch_size = 50\n",
    "# coeff pour la loi de tirage des exemple negatif\n",
    "samp_coef = 0.5\n",
    "# coeff pour le subsampling\n",
    "sub_samp = 0.00001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création des tables de probabilité de tirage (lissée) et non lissée\n",
    "\n",
    "Pour tirer les exmples négatif nous avons besoin des fréquence lissé de chaque morceau dans notre dataset. De même pour sous échantilloner les morceaux très fréquents nous avons besoin des fréquence brutes. Nous allons calculer ces deux vecteurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recupération des comptage\n",
    "counts = np.array(list(track_counts.values()),dtype='float')[order[:Vt]]\n",
    "# normalisation\n",
    "st =  counts/np.sum(counts)\n",
    "# lissage\n",
    "st_smooth = np.power(st,samp_coef)\n",
    "st_smooth = st_smooth/np.sum(st_smooth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construction du réseau word2vec\n",
    "\n",
    "Un réseau word2vec prend en entrée deux entiers correspondant à deux morceaux, ceux-ci sont plonger dans un espace latent de dimension (vector_dim) grâce a une couche de type embedding (vous devrez utilisez la même couche pour projeter les deux morceaux). Une fois ces deux vecteurs extraits le réseau doit calculer leur produit scalaire normaliser appleler cosine distance : \n",
    "\n",
    "$$cos(\\theta_{ij})=\\frac{z_i.z_j}{||z_i||||z_j||}$$ \n",
    "\n",
    "Pour réaliser ce traitement vous utiliserez une couche \"Dot\" pour \"dot product\". Le modèle utilise ensuite une couche de type sigmoid pour produire la sortie. Cette sortie vaudra 0 lorsque les deux morceaux sont des morceaux tirés aléatoirement dans l'ensemble du jeu de donnée et 1 lorsqu'il aurront était extraits de la même playslist. <span style=\"color:red\">A vous de créer le modèle keras Track2Vec correspondant à cette architecture.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-28 17:49:45.722639: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-03-28 17:49:45.722709: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-03-28 17:49:45.722732: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (tom-GF63-Thin-10SC): /proc/driver/nvidia/version does not exist\n",
      "2022-03-28 17:49:45.722960: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# entrée deux entier (couple de morceaux)\n",
    "input_target = Input((1,), dtype='int32')\n",
    "input_context = Input((1,), dtype='int32')\n",
    "\n",
    "# a vous de compléter\n",
    "embedded = Embedding(Vt, vector_dim, name=\"embedding-input\")\n",
    "embedded_target = embedded(input_target)\n",
    "embedded_context = embedded(input_context)\n",
    "dot_product = Dot(axes=1, normalize=True, name=\"dot\")([embedded_target, embedded_context])\n",
    "output = Dense(1, activation='sigmoid',name=\"classif\")(dot_product)\n",
    "\n",
    "# definition du modèle\n",
    "Track2Vec = Model(inputs=[input_target, input_context], outputs=output)\n",
    "Track2Vec.compile(loss='binary_crossentropy', optimizer='adam',metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " embedding-input (Embedding)    (None, 1, 30)        3697230     ['input_1[0][0]',                \n",
      "                                                                  'input_2[0][0]']                \n",
      "                                                                                                  \n",
      " dot (Dot)                      (None, 30, 30)       0           ['embedding-input[0][0]',        \n",
      "                                                                  'embedding-input[1][0]']        \n",
      "                                                                                                  \n",
      " classif (Dense)                (None, 30, 1)        31          ['dot[0][0]']                    \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3,697,261\n",
      "Trainable params: 3,697,261\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Track2Vec.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création du générateur de données\n",
    "\n",
    "Pour apprendre la couche de projection au coeur de notre modèle nous allons construire une générateur d'exemples positifs et négatifs de pair de morceaux proche ou aléatoires issues de nos données d'entrainement. La fonction suivante va permettre de générer de tels exemples a partir d'une playlist (seq) fournies en entrées. Cette fonction va tout d'abord construire tout les couples de morceau pouvant être extraient de la séquences s'ils se situent à moins de (windows) disance l'un de l'autres. Ces paires constitueront les paires positives. Les paires concernant deux morceaux très fréquents seront supprimer avec une probabilité qui dépendra de leur fréquences. Enfin un nombre d'exemple négatifs (correpondant neg_samples * nombre d'exemple positif) vont être tirés aléatoirement en utilisant la table de tirage (neg_sampling_table). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fonction générant les données associé a une séquence\n",
    "# seq : séquence d'entrée\n",
    "# neg_samples : nombre d'exemple négatif générés par example positif\n",
    "# neg_sampling_table : probabilité de tirage des exemples négatif\n",
    "# sub sampling_table : probabilité servant a sous échantilloner\n",
    "# sub_t : paramètre de sous échantillonage\n",
    "def word2vecSampling(seq,window,neg_samples,neg_sampling_table,sub_sampling_table,sub_t):\n",
    "    # taille du vocabulaire\n",
    "    V = len(neg_sampling_table)\n",
    "    # créations des paires positives a partir de la séquence\n",
    "    positives = skipgrams(sequence=seq, vocabulary_size=V, window_size=window,negative_samples=0)\n",
    "    ppairs    = np.array(positives[0])\n",
    "    # sous échantillonage\n",
    "    if (ppairs.shape[0]>0):\n",
    "        f = sub_sampling_table[ppairs[:,0]]\n",
    "        subprob = ((f-sub_t)/f)-np.sqrt(sub_t/f)\n",
    "        tokeep = (subprob<np.random.uniform(size=subprob.shape[0])) | (subprob<0)\n",
    "        ppairs = ppairs[tokeep,:]\n",
    "    nbneg     = ppairs.shape[0]*neg_samples\n",
    "    # tirage des paires négatives\n",
    "    if (nbneg > 0):\n",
    "        negex     = np.random.choice(V, nbneg, p=neg_sampling_table)\n",
    "        negexcontext = np.repeat(ppairs[:,0],neg_samples)\n",
    "        npairs    = np.transpose(np.stack([negexcontext,negex]))\n",
    "        pairs     = np.concatenate([ppairs,npairs],axis=0)\n",
    "        labels    = np.concatenate([np.repeat(1,ppairs.shape[0]),np.repeat(0,nbneg)])\n",
    "        perm      = np.random.permutation(len(labels))\n",
    "        res = [pairs[perm,:],labels[perm]]\n",
    "    else:\n",
    "        res=[[],[]]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">Utilisez cette fonction pour constuire un générateur \"track_ns_generator\" de données qui va générer des exemples positifs et négatifs à partir de \"nbm\" playlists tirées aléatoirement dans le jeu de données \"corpus_num\" fournis en entrée. </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13290\n",
      "13290\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([array([112347, 112347,   3925, ...,  21069, 108204,  16649]),\n",
       "  array([ 3925, 39091,  3881, ...,  7133,  5030, 16838])],\n",
       " array([[1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        ...,\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]], dtype=float32))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# définition du générateur de couple de morceaux (y=0 <-> aléatoire, y=1 <-> proche dans une playlist)\n",
    "import random\n",
    "def track_ns_generator(corpus_num,nbm):\n",
    "    #while True :\n",
    "    # tirage de nbm playlist dans corpus_num\n",
    "    x1 = []\n",
    "    x2 = []\n",
    "    y = []\n",
    "    for i in range(nbm) :\n",
    "        playlist = random.choice(corpus_num)\n",
    "        # création des données x et y \n",
    "        xa, ya = word2vecSampling(playlist, window_width, neg_sample, st, st_smooth, sub_samp)\n",
    "        for elem in xa :\n",
    "            x1.append(elem[0])\n",
    "            x2.append(elem[1])\n",
    "        for elem in ya :\n",
    "            y.append(elem)\n",
    "    x = [np.array(x1), np.array(x2)]\n",
    "    y = np.asarray(y).astype('float32').reshape((-1,1))\n",
    "    print(len(y))\n",
    "    print(len(x1))\n",
    "    return (x,y) \n",
    "\n",
    "track_ns_generator(play_app, min_batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apprentissage \n",
    "Vous devriez maintenant être en mesure d'apprendre votre premier modèle avec le code suivant. Cela devrait durer entre 15 et 30 min."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11286\n",
      "11286\n",
      "Epoch 1/60\n",
      "  2/200 [..............................] - ETA: 10s - loss: 0.8806 - accuracy: 0.4956"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tom/anaconda3/lib/python3.9/site-packages/tensorflow/python/data/ops/structured_function.py:264: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 11s 55ms/step - loss: 0.7840 - accuracy: 0.5234\n",
      "Epoch 2/60\n",
      "200/200 [==============================] - 12s 60ms/step - loss: 0.6385 - accuracy: 0.6527\n",
      "Epoch 3/60\n",
      "200/200 [==============================] - 11s 54ms/step - loss: 0.5728 - accuracy: 0.8197\n",
      "Epoch 4/60\n",
      "200/200 [==============================] - 11s 54ms/step - loss: 0.5387 - accuracy: 0.8317\n",
      "Epoch 5/60\n",
      "200/200 [==============================] - 11s 54ms/step - loss: 0.5116 - accuracy: 0.8354\n",
      "Epoch 6/60\n",
      "200/200 [==============================] - 11s 54ms/step - loss: 0.4955 - accuracy: 0.8327\n",
      "Epoch 7/60\n",
      "200/200 [==============================] - 11s 54ms/step - loss: 0.4809 - accuracy: 0.8341\n",
      "Epoch 8/60\n",
      "200/200 [==============================] - 11s 54ms/step - loss: 0.4723 - accuracy: 0.8330\n",
      "Epoch 9/60\n",
      "200/200 [==============================] - 11s 54ms/step - loss: 0.4679 - accuracy: 0.8309\n",
      "Epoch 10/60\n",
      "200/200 [==============================] - 11s 54ms/step - loss: 0.4571 - accuracy: 0.8357\n",
      "Epoch 11/60\n",
      "200/200 [==============================] - 11s 55ms/step - loss: 0.4582 - accuracy: 0.8321\n",
      "Epoch 12/60\n",
      "200/200 [==============================] - 11s 54ms/step - loss: 0.4558 - accuracy: 0.8323\n",
      "Epoch 13/60\n",
      "200/200 [==============================] - 11s 54ms/step - loss: 0.4499 - accuracy: 0.8354\n",
      "Epoch 14/60\n",
      "200/200 [==============================] - 11s 55ms/step - loss: 0.4533 - accuracy: 0.8324\n",
      "Epoch 15/60\n",
      "200/200 [==============================] - 11s 56ms/step - loss: 0.4499 - accuracy: 0.8343\n",
      "Epoch 16/60\n",
      "200/200 [==============================] - 11s 55ms/step - loss: 0.4510 - accuracy: 0.8333\n",
      "Epoch 17/60\n",
      "200/200 [==============================] - 11s 55ms/step - loss: 0.4528 - accuracy: 0.8320\n",
      "Epoch 18/60\n",
      "200/200 [==============================] - 11s 55ms/step - loss: 0.4512 - accuracy: 0.8330\n",
      "Epoch 19/60\n",
      "200/200 [==============================] - 11s 56ms/step - loss: 0.4500 - accuracy: 0.8338\n",
      "Epoch 20/60\n",
      "200/200 [==============================] - 11s 55ms/step - loss: 0.4488 - accuracy: 0.8345\n",
      "Epoch 21/60\n",
      "200/200 [==============================] - 11s 55ms/step - loss: 0.4494 - accuracy: 0.8341\n",
      "Epoch 22/60\n",
      "200/200 [==============================] - 11s 55ms/step - loss: 0.4511 - accuracy: 0.8330\n",
      "Epoch 23/60\n",
      "200/200 [==============================] - 11s 55ms/step - loss: 0.4507 - accuracy: 0.8332\n",
      "Epoch 24/60\n",
      "200/200 [==============================] - 11s 55ms/step - loss: 0.4542 - accuracy: 0.8311\n",
      "Epoch 25/60\n",
      "200/200 [==============================] - 11s 55ms/step - loss: 0.4469 - accuracy: 0.8356\n",
      "Epoch 26/60\n",
      "200/200 [==============================] - 11s 55ms/step - loss: 0.4538 - accuracy: 0.8313\n",
      "Epoch 27/60\n",
      "200/200 [==============================] - 11s 55ms/step - loss: 0.4495 - accuracy: 0.8340\n",
      "Epoch 28/60\n",
      "200/200 [==============================] - 11s 55ms/step - loss: 0.4493 - accuracy: 0.8341\n",
      "Epoch 29/60\n",
      "200/200 [==============================] - 11s 55ms/step - loss: 0.4525 - accuracy: 0.8321\n",
      "Epoch 30/60\n",
      "200/200 [==============================] - 11s 55ms/step - loss: 0.4504 - accuracy: 0.8334\n",
      "Epoch 31/60\n",
      "200/200 [==============================] - 11s 55ms/step - loss: 0.4482 - accuracy: 0.8348\n",
      "Epoch 32/60\n",
      "200/200 [==============================] - 11s 55ms/step - loss: 0.4506 - accuracy: 0.8333\n",
      "Epoch 33/60\n",
      "200/200 [==============================] - 11s 55ms/step - loss: 0.4493 - accuracy: 0.8341\n",
      "Epoch 34/60\n",
      "200/200 [==============================] - 11s 55ms/step - loss: 0.4518 - accuracy: 0.8325\n",
      "Epoch 35/60\n",
      "200/200 [==============================] - 11s 55ms/step - loss: 0.4490 - accuracy: 0.8343\n",
      "Epoch 36/60\n",
      "200/200 [==============================] - 11s 56ms/step - loss: 0.4565 - accuracy: 0.8296\n",
      "Epoch 37/60\n",
      "200/200 [==============================] - 11s 56ms/step - loss: 0.4507 - accuracy: 0.8332\n",
      "Epoch 38/60\n",
      "200/200 [==============================] - 11s 55ms/step - loss: 0.4496 - accuracy: 0.8339\n",
      "Epoch 39/60\n",
      "200/200 [==============================] - 11s 55ms/step - loss: 0.4457 - accuracy: 0.8363\n",
      "Epoch 40/60\n",
      "200/200 [==============================] - 11s 56ms/step - loss: 0.4510 - accuracy: 0.8331\n",
      "Epoch 41/60\n",
      "200/200 [==============================] - 11s 55ms/step - loss: 0.4547 - accuracy: 0.8308\n",
      "Epoch 42/60\n",
      "200/200 [==============================] - 11s 55ms/step - loss: 0.4494 - accuracy: 0.8340\n",
      "Epoch 43/60\n",
      "200/200 [==============================] - 11s 56ms/step - loss: 0.4462 - accuracy: 0.8361\n",
      "Epoch 44/60\n",
      "200/200 [==============================] - 11s 55ms/step - loss: 0.4564 - accuracy: 0.8297\n",
      "Epoch 45/60\n",
      "200/200 [==============================] - 11s 56ms/step - loss: 0.4476 - accuracy: 0.8352\n",
      "Epoch 46/60\n",
      "200/200 [==============================] - 12s 59ms/step - loss: 0.4544 - accuracy: 0.8310\n",
      "Epoch 47/60\n",
      "200/200 [==============================] - 11s 56ms/step - loss: 0.4465 - accuracy: 0.8358\n",
      "Epoch 48/60\n",
      "200/200 [==============================] - 11s 54ms/step - loss: 0.4502 - accuracy: 0.8336\n",
      "Epoch 49/60\n",
      "200/200 [==============================] - 11s 54ms/step - loss: 0.4467 - accuracy: 0.8357\n",
      "Epoch 50/60\n",
      "200/200 [==============================] - 11s 54ms/step - loss: 0.4552 - accuracy: 0.8304\n",
      "Epoch 51/60\n",
      "200/200 [==============================] - 11s 54ms/step - loss: 0.4461 - accuracy: 0.8361\n",
      "Epoch 52/60\n",
      "200/200 [==============================] - 11s 56ms/step - loss: 0.4543 - accuracy: 0.8310\n",
      "Epoch 53/60\n",
      "200/200 [==============================] - 11s 55ms/step - loss: 0.4513 - accuracy: 0.8328\n",
      "Epoch 54/60\n",
      "200/200 [==============================] - 11s 55ms/step - loss: 0.4479 - accuracy: 0.8350\n",
      "Epoch 55/60\n",
      "200/200 [==============================] - 11s 55ms/step - loss: 0.4517 - accuracy: 0.8326\n",
      "Epoch 56/60\n",
      "200/200 [==============================] - 11s 55ms/step - loss: 0.4529 - accuracy: 0.8318\n",
      "Epoch 57/60\n",
      "200/200 [==============================] - 11s 55ms/step - loss: 0.4486 - accuracy: 0.8345\n",
      "Epoch 58/60\n",
      "200/200 [==============================] - 11s 56ms/step - loss: 0.4486 - accuracy: 0.8346\n",
      "Epoch 59/60\n",
      "200/200 [==============================] - 11s 55ms/step - loss: 0.4522 - accuracy: 0.8323\n",
      "Epoch 60/60\n",
      " 80/200 [===========>..................] - ETA: 6s - loss: 0.4533 - accuracy: 0.8316WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 12000 batches). You may need to use the repeat() function when building your dataset.\n",
      "200/200 [==============================] - 4s 22ms/step - loss: 0.4533 - accuracy: 0.8316\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "xx, yy = track_ns_generator(play_app,min_batch_size)\n",
    "tensorflow.config.run_functions_eagerly(True)\n",
    "hist = Track2Vec.fit(xx, yy, steps_per_epoch = 200,epochs=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sauvegarde de l'espace latent\n",
    "Nous pouvons une fois l'apprentissage effectué sauvegarder la position des morceaux dans l'espace latent avec le code suivant:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# récupérations des positions des morceaux dans l'espace de projection\n",
    "vectors_tracks = Track2Vec.get_weights()[0]\n",
    "with open('latent_positions.npy', 'wb') as f:\n",
    "    np.save(f, vectors_tracks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Et nous pouvons la recharger avec le code suivant :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors_tracks=np.load(\"latent_positions.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilisation en complétion et évaluation\n",
    "Nous pouvons maintenant nous servir de cet espace pour faire des suggestions. <span style=\"color:red\">Construisez une fonction predict_batch qui prend en entrée un vecteur de numéro de morceaux (seeds), (s) un nombre de proposition a faire, les vecteurs des morceaux dans l'espace latent X et un kd-tree permettant d'accélérer les calculs de plus proche voisins. Pour faire ses propisitions cette fonctions retournera les indices des s plus proche voisins de chaque seeds. </span> Pour que ces predictions ne prennent pas trop de temps vous vous servirez d'un kd-tree (disponnible dans scikit learn) pour accélrer la recherche des plus proche voisins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KDTree\n",
    "kdt = KDTree(vectors_tracks, leaf_size=10, metric='euclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_batch(seeds,k,X,kdt):\n",
    "    # TODO\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">Utilisez cette fonction pour proposer des morceaux pour compléter les playlist du jeu de données de validation (les seeds correspondent à la première colone de play_val).</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = predict_batch(play_val[:,0],10,vectors_tracks,kdt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">Comparez ces suggestions avec la seconde colonne de play_val (les morceaux effectivement présents). Pour cela vous calculerez le hit@10 qui vaut 1 si le morceau effectivement présent dans la playlist fait partie des 10 propositions (ce score étant moyenné sur l'ensemble de validation) et le NDCG@10 (Normalized Discounted Cumulative Gain) qui prend en compte l'ordre des propositions. Ce second score vaut $1/log2(k+1)$ si la proposition k (k entre 1 et 10) est la proposition correcte et 0 si aucne proposition n'est correcte. Comme précedement vous calulerez le score moyen sur l'ensemble de validation. </span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'NDGCatK' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_381942/295098093.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mNDGCatK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'NDGCatK' is not defined"
     ]
    }
   ],
   "source": [
    "NDGCatK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HitatK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tunning des hyper paramètres\n",
    "\n",
    "<span style=\"color:red\">Vous pouvez maintenant essayer de faire varier les hyper paramètres pour améliorer vos performances. Attention au temps de calcul préparez une grille avec une dizaine de configurations différentes et évaluez chacune d'entre elles sur votre ensemblede validation.\n",
    "Evaluez les performances finales de la meilleure configuration trouvée sur l'ensemble de test. N'oubliez pas de sauvergader vos résultats.</span>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus, un peu de musique\n",
    "\n",
    "Le fichier TrackArtists contient des méta.données sur les morceaux et les artiste pour un sous ensemble des 300000 morceaux présent dans le dataset. Nous pouvons nous en servir pour recherchez le numéro d'un morceau a partir de son titre:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "tr_meta=pd.read_csv(\"./TracksArtists.csv\")\n",
    "joindf = pd.DataFrame({\"track_id\":tracks_list_ordered[:Vt],\"index\":range(Vt)})\n",
    "meta = tr_meta.merge(joindf, left_on=\"track_id\",right_on=\"track_id\")\n",
    "meta.set_index(\"index\",inplace=True)\n",
    "meta[[\"title\",\"name\",\"preview\",\"track_id\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_track(title):\n",
    "    return meta.loc[meta[\"title\"]==title,:].index[0]\n",
    "\n",
    "tr=find_track(\"Hexagone\")\n",
    "tr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Radio\n",
    "\n",
    "L'api de deeezer permet de récupérer des informations sur les morceaux du dataset a partit de leur id deezer. Parmis ces infos lorsqu'elle est disponnible une url d'écoute d'un extrait gratuit est fournies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request, json \n",
    "def gettrackinfo(number):\n",
    "    track_url =  \"https://api.deezer.com/track/{}\".format(tracks_list_ordered[number].split(\"_\")[1])\n",
    "    with urllib.request.urlopen(track_url) as url:\n",
    "        data = json.loads(url.read().decode())\n",
    "    return data\n",
    "track_apidata = gettrackinfo(find_track(\"Hexagone\"))\n",
    "track_apidata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons donc nous en servir pour écouter un extrait :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Audio, clear_output\n",
    "display(Audio(track_apidata[\"preview\"],autoplay=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">Créez une fonction radio qui prend en entrée un numéro de morceau dans le dataset et lance une serie de nb_track morceaux en tirant aléatoirement dans le voisinage du morceau courant le morceau suivant a écouter. La taille du voisinage sera paramétrable et vous supprimerez des propositions les morceaux déjà écouté. Vous traiterez les exceptions si le morceau ne dispose pas d'extrait disponnible. Vous povez supprimer le morceau courant avec la fonction clear_display.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def start_radio(seed,nb_candidates,duration,nbsteps=20):\n",
    "    print(meta.loc[seed,\"title\"])\n",
    "    display(Audio(meta.loc[seed,\"preview\"],autoplay=True))\n",
    "    time.sleep(duration)\n",
    "    clear_output()\n",
    "    already_played = [seed]\n",
    "    for i in range(nbsteps):\n",
    "        try:\n",
    "            # TODO\n",
    "        except:\n",
    "            print(\"track not found\")\n",
    "            pass\n",
    "        clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_radio(find_track(\"Hexagone\"),5,5,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
